import sounddevice as sd
from scipy.io.wavfile import write
import whisper
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import ssl

ssl._create_default_https_context = ssl._create_unverified_context


# å‚æ•°è®¾ç½®
duration = 10  # å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
samplerate = 16000  # Whisper æ¨èé‡‡æ ·ç‡
audio_filename = "recorded.wav"

# 1. å½•éŸ³
print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆ{duration} ç§’ï¼‰...")
recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16')
sd.wait()
write(audio_filename, samplerate, recording)
print(f"âœ… å½•éŸ³å®Œæˆï¼Œæ–‡ä»¶ä¿å­˜ä¸ºï¼š{audio_filename}")

# 2. Whisper æœ¬åœ°è¯†åˆ«
print("ğŸ§  æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹å¹¶è¯†åˆ«è¯­éŸ³...")
whisper_model = whisper.load_model("large-v3")  # æˆ– "base", "small", "medium"
result = whisper_model.transcribe(audio_filename, language="en")
recognized_text = result["text"]
print("ğŸ§ è¯†åˆ«ç»“æœï¼š", recognized_text)

# 3. ä½¿ç”¨ Qwen æœ¬åœ°ç”Ÿæˆå›ç­”
print("ğŸ¤– æ­£åœ¨åŠ è½½ Qwen æ¨¡å‹...")
# qwen_model_id = "Qwen/Qwen1.5-1.8B-Chat" Qwen3-8B
qwen_model_id = "Qwen/Qwen3-4B"  # æ›¿æ¢ä¸ºä½ ä½¿ç”¨çš„ Qwen æ¨¡å‹ ID
tokenizer = AutoTokenizer.from_pretrained(qwen_model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(qwen_model_id, trust_remote_code=True, device_map="auto").eval()

# æ„é€  Prompt
system_prompt = "<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åŠ©æ‰‹ã€‚<|im_end|>"
user_prompt = f"<|im_start|>user\n{recognized_text}<|im_end|>\n<|im_start|>assistant\n"
prompt = system_prompt + "\n" + user_prompt

# æ¨¡å‹ç”Ÿæˆå›ç­”
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(
    **inputs,
    max_new_tokens=1024,
    do_sample=True,
    temperature=0.8,
    top_p=0.9
)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
if "<|im_start|>assistant\n" in response:
    response_text = response.split("<|im_start|>assistant\n")[-1]
else:
    response_text = response

print("ğŸ—£ï¸ Qwen å›å¤ï¼š", response_text.strip())
